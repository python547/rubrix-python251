{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing: modeling dataset as multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Running setup.py install for sacremoses ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for jsonnet ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for overrides ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for nltk ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for prometheus-flask-exporter ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for sqlalchemy ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for Mako ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for alembic ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for databricks-cli ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for flatdict ... \u001b[?25ldone\n",
      "\u001b[?25h  Found existing installation: idna 3.1\n",
      "    Uninstalling idna-3.1:\n",
      "      Successfully uninstalled idna-3.1\n",
      "  Running setup.py install for nvidia-ml-py3 ... \u001b[?25ldone\n",
      "\u001b[?25h  Running setup.py install for gpustat ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed Mako-1.1.4 Werkzeug-1.0.1 aiohttp-3.7.3 aiohttp-cors-0.7.0 aioredis-1.3.1 alembic-1.5.4 allennlp-1.3.0 async-timeout-3.0.1 azure-core-1.11.0 azure-storage-blob-12.7.1 beautifulsoup4-4.9.3 biome-text-2.0.0 blessings-1.7 blis-0.7.4 boto3-1.17.7 botocore-1.20.7 cached-property-1.5.2 cachetools-4.2.1 cachey-0.2.1 captum-0.2.0 catalogue-1.0.0 click-7.1.2 cloudpickle-1.6.0 colorama-0.4.4 colorful-0.5.4 cryptography-3.4.5 cycler-0.10.0 cymem-2.0.5 dask-2021.2.0 databricks-cli-0.14.1 datasets-1.1.3 dill-0.3.3 distributed-2.17.0 docker-4.4.1 elasticsearch-7.1.0 fastapi-0.55.1 filelock-3.0.12 flask-1.1.2 flask-cors-3.0.10 flatdict-4.0.1 fsspec-0.8.5 gevent-20.9.0 gitdb-4.0.5 gitpython-3.1.13 google-3.0.0 google-api-core-1.26.0 google-auth-1.26.1 googleapis-common-protos-1.52.0 gorilla-0.3.0 gpustat-0.6.0 greenlet-1.0.0 grpcio-1.35.0 gunicorn-20.0.4 h5py-3.1.0 heapdict-1.0.1 hiredis-1.1.0 httptools-0.1.1 idna-2.10 iniconfig-1.1.1 ipywidgets-7.5.1 isodate-0.6.0 itsdangerous-1.1.0 jmespath-0.10.0 joblib-1.0.1 jsonnet-0.17.0 jsonpickle-2.0.0 kiwisolver-1.3.1 lxml-4.5.2 matplotlib-3.3.4 mlflow-1.9.1 msgpack-1.0.2 msrest-0.6.21 multidict-5.1.0 multiprocess-0.70.11.1 murmurhash-1.0.5 nltk-3.5 nvidia-ml-py3-7.352.0 oauthlib-3.1.0 opencensus-0.7.12 opencensus-context-0.1.2 overrides-3.1.0 pandas-1.1.5 pillow-8.1.0 plac-1.1.3 pluggy-0.13.1 preshed-3.0.5 prometheus-flask-exporter-0.18.1 protobuf-3.14.0 psutil-5.8.0 py-1.10.0 py-spy-0.3.4 pyarrow-3.0.0 pyasn1-0.4.8 pyasn1-modules-0.2.8 pydantic-1.7.3 pytest-6.2.2 python-editor-1.0.4 pyyaml-5.4.1 querystring-parser-1.2.4 ray-1.0.1.post1 redis-3.4.1 regex-2020.11.13 requests-oauthlib-1.3.0 rsa-4.7 s3fs-0.4.2 s3transfer-0.3.4 sacremoses-0.0.43 scikit-learn-0.24.1 scipy-1.6.0 sentencepiece-0.1.95 smmap-3.0.5 sortedcontainers-2.3.0 soupsieve-2.2 spacy-2.3.5 sqlalchemy-1.3.13 sqlparse-0.4.1 srsly-1.0.5 starlette-0.13.2 tabulate-0.8.7 tblib-1.7.0 tensorboardX-2.1 thinc-7.4.5 threadpoolctl-2.1.0 tokenizers-0.9.4 toml-0.10.2 toolz-0.11.1 torch-1.7.1 tqdm-4.56.2 transformers-4.0.1 uvicorn-0.11.8 uvloop-0.15.0 wasabi-0.8.2 websocket-client-0.57.0 websockets-8.1 widgetsnbextension-3.5.1 xlrd-1.2.0 xxhash-2.0.0 yarl-1.6.3 zict-2.0.0 zope.event-4.5.0 zope.interface-5.2.0\n",
      "\u001b[33mYou are using pip version 19.0.3, however version 21.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install biome-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>misogyny_category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2895</td>\n",
       "      <td>2278</td>\n",
       "      <td>@perradesatan @iamjoseAM Pues tengo todo el dí...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>965</td>\n",
       "      <td>659</td>\n",
       "      <td>@MirandaLanda22 Ya callate pinche puta y celeb...</td>\n",
       "      <td>1</td>\n",
       "      <td>dominance</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>569</td>\n",
       "      <td>1118</td>\n",
       "      <td>@TowandaRebels esto pasa cuando no tienes ni p...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>216</td>\n",
       "      <td>2848</td>\n",
       "      <td>Me voy a meter en un tema delicado pero ya fue...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2254</td>\n",
       "      <td>1442</td>\n",
       "      <td>QUE OS FOLLEN A TODOS VEO PORNO EN MI CASA Y M...</td>\n",
       "      <td>1</td>\n",
       "      <td>sexual_harassment</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2805</th>\n",
       "      <td>3236</td>\n",
       "      <td>2611</td>\n",
       "      <td>@AmericaMirandaR Puta, tantos años de ser bff ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2806</th>\n",
       "      <td>2896</td>\n",
       "      <td>2041</td>\n",
       "      <td>@TiaFeminazi Y lo que no es la voz, ¿Eh? ¡Movi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2807</th>\n",
       "      <td>2626</td>\n",
       "      <td>885</td>\n",
       "      <td>Me preguntaron por qué mi perro tiene collar r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2808</th>\n",
       "      <td>3255</td>\n",
       "      <td>306</td>\n",
       "      <td>// Hostia puta, si tú eres del Fake Danganronp...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2809</th>\n",
       "      <td>1626</td>\n",
       "      <td>313</td>\n",
       "      <td>No le encuentro la puta gracia a los memes y v...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2810 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0    id                                               text  \\\n",
       "0           2895  2278  @perradesatan @iamjoseAM Pues tengo todo el dí...   \n",
       "1            965   659  @MirandaLanda22 Ya callate pinche puta y celeb...   \n",
       "2            569  1118  @TowandaRebels esto pasa cuando no tienes ni p...   \n",
       "3            216  2848  Me voy a meter en un tema delicado pero ya fue...   \n",
       "4           2254  1442  QUE OS FOLLEN A TODOS VEO PORNO EN MI CASA Y M...   \n",
       "...          ...   ...                                                ...   \n",
       "2805        3236  2611  @AmericaMirandaR Puta, tantos años de ser bff ...   \n",
       "2806        2896  2041  @TiaFeminazi Y lo que no es la voz, ¿Eh? ¡Movi...   \n",
       "2807        2626   885  Me preguntaron por qué mi perro tiene collar r...   \n",
       "2808        3255   306  // Hostia puta, si tú eres del Fake Danganronp...   \n",
       "2809        1626   313  No le encuentro la puta gracia a los memes y v...   \n",
       "\n",
       "      label  misogyny_category   target  \n",
       "0         1  sexual_harassment   active  \n",
       "1         1          dominance   active  \n",
       "2         0                  0        0  \n",
       "3         0                  0        0  \n",
       "4         1  sexual_harassment  passive  \n",
       "...     ...                ...      ...  \n",
       "2805      0                  0        0  \n",
       "2806      0                  0        0  \n",
       "2807      0                  0        0  \n",
       "2808      1          discredit   active  \n",
       "2809      0                  0        0  \n",
       "\n",
       "[2810 rows x 6 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/miso_training_ds.csv') ; df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df):\n",
    "    preproc_ds = []\n",
    "    for i,r in df.iterrows():\n",
    "        if r.label == 1:\n",
    "            preproc_ds.append({\n",
    "                'id': r.id,\n",
    "                'text': r.text,\n",
    "                'label': [r.misogyny_category, r.target]\n",
    "            })\n",
    "        else:\n",
    "            preproc_ds.append({\n",
    "                'id': r.id,\n",
    "                'text': r.text,\n",
    "                'label': []\n",
    "        })\n",
    "    preproc_ds\n",
    "    return pd.DataFrame(preproc_ds)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = preprocess(df) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3057</td>\n",
       "      <td>@SoyPutoImbecil me he leido el mismo numero de...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1625</td>\n",
       "      <td>Dizque que no vaya a llegar un hijueputa al fi...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>57</td>\n",
       "      <td>En que se parece una mujer a un cientifico? En...</td>\n",
       "      <td>[stereotype, passive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3159</td>\n",
       "      <td>que hueva que hables de la gente asi, si tu er...</td>\n",
       "      <td>[discredit, active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3080</td>\n",
       "      <td>Que escoria de juego, se me cierra solo y no m...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2715</td>\n",
       "      <td>@edward18jgm @PunishedLivinx Tu eres el gilipo...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>2744</td>\n",
       "      <td>Mira que su ex era una chica de puta madre per...</td>\n",
       "      <td>[discredit, active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>519</td>\n",
       "      <td>La zorra de @laufer4 riéndose en la cara de mi...</td>\n",
       "      <td>[discredit, active]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>2030</td>\n",
       "      <td>No quiero poner cervezas, ni vinos, ni nada de...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>819</td>\n",
       "      <td>@LeticiaDolera Pues a esté señor le va de puta...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                                               text  \\\n",
       "0    3057  @SoyPutoImbecil me he leido el mismo numero de...   \n",
       "1    1625  Dizque que no vaya a llegar un hijueputa al fi...   \n",
       "2      57  En que se parece una mujer a un cientifico? En...   \n",
       "3    3159  que hueva que hables de la gente asi, si tu er...   \n",
       "4    3080  Que escoria de juego, se me cierra solo y no m...   \n",
       "..    ...                                                ...   \n",
       "492  2715  @edward18jgm @PunishedLivinx Tu eres el gilipo...   \n",
       "493  2744  Mira que su ex era una chica de puta madre per...   \n",
       "494   519  La zorra de @laufer4 riéndose en la cara de mi...   \n",
       "495  2030  No quiero poner cervezas, ni vinos, ni nada de...   \n",
       "496   819  @LeticiaDolera Pues a esté señor le va de puta...   \n",
       "\n",
       "                     label  \n",
       "0                       []  \n",
       "1                       []  \n",
       "2    [stereotype, passive]  \n",
       "3      [discredit, active]  \n",
       "4                       []  \n",
       "..                     ...  \n",
       "492                     []  \n",
       "493    [discredit, active]  \n",
       "494    [discredit, active]  \n",
       "495                     []  \n",
       "496                     []  \n",
       "\n",
       "[497 rows x 3 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_df =  preprocess(pd.read_csv('datasets/validation_ds.csv')) ; validation_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train baseline multilabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from biome.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = Dataset.from_pandas(train_df)\n",
    "validation_ds = Dataset.from_pandas(validation_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline.from_config({\n",
    "    \"name\": \"multilabel\",\n",
    "    \"head\": {\n",
    "        \"type\": \"TextClassification\",\n",
    "        \"multilabel\": True,\n",
    "        \"labels\": [\n",
    "            'sexual_harassment',\n",
    "             'dominance',\n",
    "             'discredit',\n",
    "             'stereotype',\n",
    "             'derailing',\n",
    "             'passive',\n",
    "             'active'\n",
    "        ]\n",
    "        \n",
    "    }\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ('dominance',\n",
       "  'stereotype',\n",
       "  'passive',\n",
       "  'discredit',\n",
       "  'derailing',\n",
       "  'sexual_harassment',\n",
       "  'active'),\n",
       " 'probabilities': (0.6362525224685669,\n",
       "  0.6272443532943726,\n",
       "  0.5087952017784119,\n",
       "  0.5075286626815796,\n",
       "  0.42596080899238586,\n",
       "  0.38110002875328064,\n",
       "  0.3777536153793335)}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(text=\"El mal querer by Rosalia\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:24:54,643 - allennlp.data.vocabulary - INFO - Fitting token dictionary from dataset.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d958b604c8a646dab3903b6c4c499dab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "building vocab: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ec5d90ea29a41c6b7844675c54a510e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading instances into memory:   0%|          | 0/2810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "663381b3bfda4bb3a50cd407c29a56cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading instances into memory:   0%|          | 0/2810 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2586947e5664428f8a3fc2c3c504a987",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading instances into memory:   0%|          | 0/497 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:12,415 - allennlp.common.params - INFO - random_seed = 13370\n",
      "2021-02-15 15:25:12,416 - allennlp.common.params - INFO - numpy_seed = 1337\n",
      "2021-02-15 15:25:12,416 - allennlp.common.params - INFO - pytorch_seed = 133\n",
      "2021-02-15 15:25:12,418 - allennlp.common.checks - INFO - Pytorch version: 1.7.1\n",
      "2021-02-15 15:25:12,454 - allennlp.common.params - INFO - type = gradient_descent\n",
      "2021-02-15 15:25:12,456 - allennlp.common.params - INFO - local_rank = 0\n",
      "2021-02-15 15:25:12,457 - allennlp.common.params - INFO - patience = 2\n",
      "2021-02-15 15:25:12,458 - allennlp.common.params - INFO - validation_metric = -loss\n",
      "2021-02-15 15:25:12,459 - allennlp.common.params - INFO - num_epochs = 20\n",
      "2021-02-15 15:25:12,460 - allennlp.common.params - INFO - cuda_device = None\n",
      "2021-02-15 15:25:12,461 - allennlp.common.params - INFO - grad_norm = None\n",
      "2021-02-15 15:25:12,462 - allennlp.common.params - INFO - grad_clipping = None\n",
      "2021-02-15 15:25:12,464 - allennlp.common.params - INFO - distributed = False\n",
      "2021-02-15 15:25:12,465 - allennlp.common.params - INFO - world_size = 1\n",
      "2021-02-15 15:25:12,467 - allennlp.common.params - INFO - num_gradient_accumulation_steps = 1\n",
      "2021-02-15 15:25:12,468 - allennlp.common.params - INFO - use_amp = False\n",
      "2021-02-15 15:25:12,470 - allennlp.common.params - INFO - no_grad = None\n",
      "2021-02-15 15:25:12,471 - allennlp.common.params - INFO - learning_rate_scheduler = None\n",
      "2021-02-15 15:25:12,473 - allennlp.common.params - INFO - momentum_scheduler = None\n",
      "2021-02-15 15:25:12,474 - allennlp.common.params - INFO - moving_average = None\n",
      "2021-02-15 15:25:12,476 - allennlp.common.params - INFO - batch_callbacks = None\n",
      "2021-02-15 15:25:12,477 - allennlp.common.params - INFO - end_callbacks = None\n",
      "2021-02-15 15:25:12,478 - allennlp.common.params - INFO - trainer_callbacks = None\n",
      "2021-02-15 15:25:12,480 - allennlp.common.params - INFO - optimizer.type = adam\n",
      "2021-02-15 15:25:12,482 - allennlp.common.params - INFO - optimizer.parameter_groups = None\n",
      "2021-02-15 15:25:12,483 - allennlp.common.params - INFO - optimizer.lr = 0.001\n",
      "2021-02-15 15:25:12,485 - allennlp.common.params - INFO - optimizer.betas = (0.9, 0.999)\n",
      "2021-02-15 15:25:12,487 - allennlp.common.params - INFO - optimizer.eps = 1e-08\n",
      "2021-02-15 15:25:12,488 - allennlp.common.params - INFO - optimizer.weight_decay = 0.0\n",
      "2021-02-15 15:25:12,490 - allennlp.common.params - INFO - optimizer.amsgrad = False\n",
      "2021-02-15 15:25:12,491 - allennlp.training.optimizers - INFO - Number of trainable parameters: 638557\n",
      "2021-02-15 15:25:12,492 - allennlp.common.util - INFO - The following parameters are Frozen (without gradient):\n",
      "2021-02-15 15:25:12,493 - allennlp.common.util - INFO - The following parameters are Tunable (with gradient):\n",
      "2021-02-15 15:25:12,495 - allennlp.common.util - INFO - _head.backbone.embedder.token_embedder_word.weight\n",
      "2021-02-15 15:25:12,496 - allennlp.common.util - INFO - _head._classification_layer.weight\n",
      "2021-02-15 15:25:12,497 - allennlp.common.util - INFO - _head._classification_layer.bias\n",
      "2021-02-15 15:25:12,498 - allennlp.common.params - INFO - checkpointer.type = default\n",
      "2021-02-15 15:25:12,500 - allennlp.common.params - INFO - checkpointer.keep_serialized_model_every_num_seconds = None\n",
      "2021-02-15 15:25:12,502 - allennlp.common.params - INFO - checkpointer.num_serialized_models_to_keep = 1\n",
      "2021-02-15 15:25:12,505 - allennlp.common.params - INFO - checkpointer.model_save_interval = None\n",
      "2021-02-15 15:25:12,506 - allennlp.common.params - INFO - tensorboard_writer.summary_interval = 100\n",
      "2021-02-15 15:25:12,508 - allennlp.common.params - INFO - tensorboard_writer.histogram_interval = None\n",
      "2021-02-15 15:25:12,509 - allennlp.common.params - INFO - tensorboard_writer.batch_size_interval = None\n",
      "2021-02-15 15:25:12,510 - allennlp.common.params - INFO - tensorboard_writer.should_log_parameter_statistics = True\n",
      "2021-02-15 15:25:12,511 - allennlp.common.params - INFO - tensorboard_writer.should_log_learning_rate = True\n",
      "2021-02-15 15:25:12,513 - allennlp.common.params - INFO - tensorboard_writer.get_batch_num_total = None\n",
      "2021-02-15 15:25:12,517 - allennlp.training.trainer - INFO - Beginning training.\n",
      "2021-02-15 15:25:12,518 - allennlp.training.trainer - INFO - Epoch 0/19\n",
      "2021-02-15 15:25:12,518 - allennlp.training.trainer - INFO - Worker 0 memory usage: 921M\n",
      "2021-02-15 15:25:12,520 - allennlp.training.trainer - INFO - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8e15425c3d94b53a0aa8a1b06dac5e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:14,269 - allennlp.training.trainer - INFO - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9dd0b8008c9a4bfbbc510fbafb0e79e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:14,371 - allennlp.training.tensorboard_writer - INFO -                        Training |  Validation\n",
      "2021-02-15 15:25:14,372 - allennlp.training.tensorboard_writer - INFO - loss               |     0.001  |     0.484\n",
      "2021-02-15 15:25:14,374 - allennlp.training.tensorboard_writer - INFO - macro/fscore       |     1.000  |     0.571\n",
      "2021-02-15 15:25:14,374 - allennlp.training.tensorboard_writer - INFO - macro/precision    |     1.000  |     0.591\n",
      "2021-02-15 15:25:14,377 - allennlp.training.tensorboard_writer - INFO - macro/recall       |     1.000  |     0.553\n",
      "2021-02-15 15:25:14,378 - allennlp.training.tensorboard_writer - INFO - worker_0_memory_MB |   921.238  |       N/A\n",
      "2021-02-15 15:25:14,385 - allennlp.training.checkpointer - INFO - Best validation performance so far. Copying weights to 'baseline_myso_clas/best.th'.\n",
      "2021-02-15 15:25:14,390 - allennlp.training.trainer - INFO - Epoch duration: 0:00:01.872792\n",
      "2021-02-15 15:25:14,391 - allennlp.training.trainer - INFO - Estimated training time remaining: 0:00:35\n",
      "2021-02-15 15:25:14,392 - allennlp.training.trainer - INFO - Epoch 1/19\n",
      "2021-02-15 15:25:14,393 - allennlp.training.trainer - INFO - Worker 0 memory usage: 929M\n",
      "2021-02-15 15:25:14,394 - allennlp.training.trainer - INFO - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8292c221f9764821b79c3dc32ca4ae81",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:15,923 - allennlp.training.trainer - INFO - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7dcafb37ba2f4cba8a7336e8e02834d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:16,002 - allennlp.training.tensorboard_writer - INFO -                        Training |  Validation\n",
      "2021-02-15 15:25:16,003 - allennlp.training.tensorboard_writer - INFO - loss               |     0.000  |     0.525\n",
      "2021-02-15 15:25:16,005 - allennlp.training.tensorboard_writer - INFO - macro/fscore       |     1.000  |     0.575\n",
      "2021-02-15 15:25:16,006 - allennlp.training.tensorboard_writer - INFO - macro/precision    |     1.000  |     0.604\n",
      "2021-02-15 15:25:16,007 - allennlp.training.tensorboard_writer - INFO - macro/recall       |     1.000  |     0.549\n",
      "2021-02-15 15:25:16,009 - allennlp.training.tensorboard_writer - INFO - worker_0_memory_MB |   929.180  |       N/A\n",
      "2021-02-15 15:25:16,017 - allennlp.training.trainer - INFO - Epoch duration: 0:00:01.625453\n",
      "2021-02-15 15:25:16,018 - allennlp.training.trainer - INFO - Estimated training time remaining: 0:00:31\n",
      "2021-02-15 15:25:16,019 - allennlp.training.trainer - INFO - Epoch 2/19\n",
      "2021-02-15 15:25:16,020 - allennlp.training.trainer - INFO - Worker 0 memory usage: 929M\n",
      "2021-02-15 15:25:16,020 - allennlp.training.trainer - INFO - Training\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82b7cc9987644841b4dfedd2d799f99d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/176 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:17,614 - allennlp.training.trainer - INFO - Validating\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eefc048db0148119b61eac713fcbeb4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-02-15 15:25:17,705 - allennlp.training.trainer - INFO - Ran out of patience.  Stopping training.\n",
      "2021-02-15 15:25:17,706 - allennlp.training.checkpointer - INFO - loading best weights\n",
      "2021-02-15 15:25:17,710 - allennlp.models.archival - INFO - archiving weights and vocabulary to baseline_myso_clas/model.tar.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingResults(model_path='baseline_myso_clas/model.tar.gz', metrics={'best_epoch': 0, 'peak_worker_0_memory_MB': 929.1796875, 'training_duration': '0:00:03.492131', 'training_start_epoch': 0, 'training_epochs': 1, 'epoch': 1, 'training_macro/precision': 1.0, 'training_macro/recall': 1.0, 'training_macro/fscore': 1.0, 'training_loss': 0.00048137247238793697, 'training_worker_0_memory_MB': 929.1796875, 'validation_macro/precision': 0.6040268456375839, 'validation_macro/recall': 0.5487804878048781, 'validation_macro/fscore': 0.5750798722044729, 'validation_loss': 0.5253122457179416, 'best_validation_macro/precision': 0.591304347826087, 'best_validation_macro/recall': 0.5528455284552846, 'best_validation_macro/fscore': 0.5714285714285715, 'best_validation_loss': 0.48414638015674427})"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.train(training=train_ds, validation=validation_ds, output=\"baseline_myso_clas\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'labels': ('active',\n",
       "  'dominance',\n",
       "  'stereotype',\n",
       "  'sexual_harassment',\n",
       "  'passive',\n",
       "  'discredit',\n",
       "  'derailing'),\n",
       " 'probabilities': (0.9498988389968872,\n",
       "  0.9026820659637451,\n",
       "  0.686039388179779,\n",
       "  0.6391904950141907,\n",
       "  0.42101290822029114,\n",
       "  0.3665285110473633,\n",
       "  0.3359130322933197)}"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.predict(text=\"Rosalia a fregar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring training data in Rubric (new biome app + API)\n",
    "\n",
    "This only a prototype for how a python wrapper could look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rubric import rubric\n",
    "from observe.models import * \n",
    "api_key = \"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJAcmVjb2duYWkiLCJleHAiOjE2MTQ0NTgzNjl9.PlS29RTTrPMKz0FIWO4Qwk_9U_i1q5ZC_OVHbDqRIaU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AuthenticatedClient(base_url='https://observe-dev.biome.recogn.ai', cookies={}, headers={}, timeout=20, token='eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJAcmVjb2duYWkiLCJleHAiOjE2MTQ0NTgzNjl9.PlS29RTTrPMKz0FIWO4Qwk_9U_i1q5ZC_OVHbDqRIaU')\n"
     ]
    }
   ],
   "source": [
    "rubric.init(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i,r in df.iterrows():\n",
    "    record = TextClassificationRecord.from_dict({\n",
    "        \"id\":  r.id,\n",
    "        \"inputs\": {\"text\": r.text},\n",
    "        \"multi_label\": True\n",
    "     })\n",
    "    if len(r.label) > 0:\n",
    "        record[\"annotation\"] = {\n",
    "             \"agent\": \"dvilasuero\",\n",
    "             \"labels\": [{\"class\": label} for label in r.label ],\n",
    "             \n",
    "         }\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_train', processed=10, failed=0, additional_properties={})\n"
     ]
    }
   ],
   "source": [
    "rubric.log(records, dataset=\"es_multilabel_mysogyny_train\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring predictions overdf = pd.read_csv('datasets/miso_training_ds.csv') ; df validation data in Rubric (new biome app + API)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>misogyny_category</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2807</td>\n",
       "      <td>3057</td>\n",
       "      <td>@SoyPutoImbecil me he leido el mismo numero de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>406</td>\n",
       "      <td>1625</td>\n",
       "      <td>Dizque que no vaya a llegar un hijueputa al fi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2989</td>\n",
       "      <td>57</td>\n",
       "      <td>En que se parece una mujer a un cientifico? En...</td>\n",
       "      <td>1</td>\n",
       "      <td>stereotype</td>\n",
       "      <td>passive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1553</td>\n",
       "      <td>3159</td>\n",
       "      <td>que hueva que hables de la gente asi, si tu er...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1798</td>\n",
       "      <td>3080</td>\n",
       "      <td>Que escoria de juego, se me cierra solo y no m...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>492</th>\n",
       "      <td>2979</td>\n",
       "      <td>2715</td>\n",
       "      <td>@edward18jgm @PunishedLivinx Tu eres el gilipo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>493</th>\n",
       "      <td>480</td>\n",
       "      <td>2744</td>\n",
       "      <td>Mira que su ex era una chica de puta madre per...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>102</td>\n",
       "      <td>519</td>\n",
       "      <td>La zorra de @laufer4 riéndose en la cara de mi...</td>\n",
       "      <td>1</td>\n",
       "      <td>discredit</td>\n",
       "      <td>active</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3035</td>\n",
       "      <td>2030</td>\n",
       "      <td>No quiero poner cervezas, ni vinos, ni nada de...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>3049</td>\n",
       "      <td>819</td>\n",
       "      <td>@LeticiaDolera Pues a esté señor le va de puta...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>497 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0    id                                               text  \\\n",
       "0          2807  3057  @SoyPutoImbecil me he leido el mismo numero de...   \n",
       "1           406  1625  Dizque que no vaya a llegar un hijueputa al fi...   \n",
       "2          2989    57  En que se parece una mujer a un cientifico? En...   \n",
       "3          1553  3159  que hueva que hables de la gente asi, si tu er...   \n",
       "4          1798  3080  Que escoria de juego, se me cierra solo y no m...   \n",
       "..          ...   ...                                                ...   \n",
       "492        2979  2715  @edward18jgm @PunishedLivinx Tu eres el gilipo...   \n",
       "493         480  2744  Mira que su ex era una chica de puta madre per...   \n",
       "494         102   519  La zorra de @laufer4 riéndose en la cara de mi...   \n",
       "495        3035  2030  No quiero poner cervezas, ni vinos, ni nada de...   \n",
       "496        3049   819  @LeticiaDolera Pues a esté señor le va de puta...   \n",
       "\n",
       "     label misogyny_category   target  \n",
       "0        0                 0        0  \n",
       "1        0                 0        0  \n",
       "2        1        stereotype  passive  \n",
       "3        1         discredit   active  \n",
       "4        0                 0        0  \n",
       "..     ...               ...      ...  \n",
       "492      0                 0        0  \n",
       "493      1         discredit   active  \n",
       "494      1         discredit   active  \n",
       "495      0                 0        0  \n",
       "496      0                 0        0  \n",
       "\n",
       "[497 rows x 6 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('datasets/validation_ds.csv') ; df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the model via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;2m✔ Linking successful\u001b[0m\n",
      "/Users/dani/recognai/biome/biome-observe-cli/venv/lib/python3.7/site-packages/en_core_web_sm\n",
      "-->\n",
      "/Users/dani/recognai/biome/biome-observe-cli/venv/lib/python3.7/site-packages/spacy/data/en\n",
      "You can now load the model via spacy.load('en')\n"
     ]
    }
   ],
   "source": [
    "pipeline_classifier = Pipeline.from_pretrained('baseline_myso_clas')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "records = []\n",
    "for i,r in validation_df.iterrows():\n",
    "    record = TextClassificationRecord.from_dict({\n",
    "        \"id\":  r.id,\n",
    "        \"inputs\": {\"text\": r.text},\n",
    "        \"multi_label\": True\n",
    "     })\n",
    "    if len(r.label) > 0:\n",
    "        record[\"annotation\"] = {\n",
    "             \"agent\": \"dvilasuero\",\n",
    "             \"labels\": [{\"class\": label} for label in r.label ],\n",
    "             \n",
    "         }\n",
    "    # Store predictions together with true labels\n",
    "    preds = pipeline_classifier.predict(text=r.text)\n",
    "    record[\"prediction\"] = {\n",
    "            \"agent\": pipeline_classifier.name, \n",
    "            \"labels\": [{\"class\": cls, \"confidence\": prob} for cls, prob in zip(preds['labels'],preds['probabilities'])]\n",
    "    }\n",
    "    records.append(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BulkResponse(dataset='es_multilabel_mysogyny_val_with_predictions', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_val_with_predictions', processed=200, failed=0, additional_properties={})\n",
      "BulkResponse(dataset='es_multilabel_mysogyny_val_with_predictions', processed=97, failed=0, additional_properties={})\n"
     ]
    }
   ],
   "source": [
    "rubric.log(records, dataset=\"es_multilabel_mysogyny_val_with_predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appendix: same with raw Python cli SDK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from observe.client import Client, AuthenticatedClient\n",
    "from observe.models import * \n",
    "from observe.api.text_classification import bulk_records, search_records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = Client(base_url=\"https://observe-dev.biome.recogn.ai\")\n",
    "client = AuthenticatedClient(\n",
    "    base_url=client.base_url, \n",
    "    token=\"eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJzdWIiOiJAcmVjb2duYWkiLCJleHAiOjE2MTQ0NTgzNjl9.PlS29RTTrPMKz0FIWO4Qwk_9U_i1q5ZC_OVHbDqRIaU\",\n",
    "    timeout=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "chunk_size= 1000\n",
    "for i in range(0, len(records), chunk_size):\n",
    "    chunk = records[i:i+chunk_size]\n",
    "    response = bulk_records.sync(client=client, json_body=TextClassificationRecordsBulk(\n",
    "        name=\"test_miso\", \n",
    "        tags=TextClassificationRecordsBulkTags.from_dict({ \n",
    "            \"type\":\"classifier\",\n",
    "            \"lang\": \"spanish\",\n",
    "            \"description\": \"Spanish sentiment classifier with `multifield inputs` (title and body)\"\n",
    "        }),\n",
    "        records=chunk\n",
    "    ))\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
